# README: Camada 3 - Agentes Locais (`local_agents/`)

Este diret√≥rio √© o cora√ß√£o da filosofia de **"Autonomia Local"** da arquitetura.

Enquanto `providers_api/` lida com APIs de nuvem (OpenAI, Google), este diret√≥rio define os **Agentes (Organismos) que rodam 100% localmente** no seu hardware.

## üõ†Ô∏è Implementa√ß√£o T√©cnica: Ollama

Todos os agentes definidos aqui s√£o projetados para rodar em um servidor de IA local.

1.  **O Servidor (`docker-compose.yml`):** O servi√ßo `ollama` √© o "host" que serve os modelos de IA (ex: `janhq/jan-v1-4b`, `mistral`, etc.).
2.  **O Cliente (`requirements.txt`):** O `AtomicEngine` usa a biblioteca `ollama` para se comunicar com o servidor.

Os arquivos `.yaml` (como `agent_ocr.yaml`) no diret√≥rio `organisms/` s√£o os arquivos de *configura√ß√£o* que dizem ao `AtomicEngine` qual modelo (`model: "mistral"`) e qual `system_prompt` (miss√£o) usar ao chamar o cliente Ollama.

## üß† A Estrat√©gia: "Mixture of Experts" (MoE)

N√≥s n√£o usamos um √∫nico modelo gigante para tudo. Em vez disso, usamos uma **"Mistura de Especialistas"** (Mixture of Experts) em n√≠vel de arquitetura. Cada agente √© um especialista otimizado para uma tarefa, criando um sistema mais eficiente, barato e poderoso.

Esta √© a nossa "Equipe Digital" de especialistas:

---

### üëë O Orquestrador (Agente Mestre)

Este √© o agente mais importante da camada, o "c√©rebro" de roteamento.

* **Agente:** `agent_mcp.yaml`
* **Modelo:** `janhq/jan-v1-4b`
* **Fun√ß√£o:** Orquestra√ß√£o (Master Context Persistence).
* **An√°lise:** Este modelo foi explicitamente **otimizado para racioc√≠nio ag√™ntico, planejamento e uso de ferramentas**. Ele entende a tarefa, consulta a `api_mcp/` (Camada 1) para obter contexto e, em seguida, **chama o especialista certo** (vis√£o, c√≥digo, OCR) para fazer o trabalho.

---

### ü§ñ A Equipe de Especialistas (Delegados)

Estes s√£o os agentes que o `agent_mcp` gerencia:

#### 1. O Documentarista (OCR Sem√¢ntico)
* **Agente:** `agent_OCR.yaml`
* **Modelo:** `nanonets-OCR2 3b`
* **Fun√ß√£o:** Leitura e Formata√ß√£o de Documentos.
* **An√°lise:** Este modelo n√£o faz apenas OCR; ele faz **OCR sem√¢ntico**. Ele √© treinado para interpretar, organizar e formatar documentos (PDFs, imagens) em **Markdown limpo e contextualizado**, entendendo tabelas, f√≥rmulas (LaTeX) e imagens. Ele transforma documentos escaneados em dados estruturados.

#### 2. O Estruturador (Texto para JSON)
* **Agente:** `agent_text_struct.yaml`
* **Modelo:** `gpt-oss-20b` (Modelo MoE)
* **Fun√ß√£o:** Produ√ß√£o e An√°lise Sem√¢ntica.
* **An√°lise:** A principal caracter√≠stica deste modelo √© o suporte a **"Structured Outputs" (Sa√≠das Estruturadas)**. Enquanto o `agent_OCR` lida com *documentos*, este agente √© o especialista em pegar texto n√£o estruturado (como um par√°grafo) e convert√™-lo em formatos de dados limpos como **JSON** ou **YAML** seguindo instru√ß√µes.

#### 3. O Vidente (Vis√£o)
* **Agente:** `agent_vision.yaml`
* **Modelo:** `qwen 2.5 vision 8b`
* **Fun√ß√£o:** An√°lise de Imagem Contextual.
* **An√°lise:** Um poderoso Modelo de Linguagem e Vis√£o (VLM). √â especializado em **reconhecimento de imagens, localiza√ß√£o de objetos e OCR b√°sico**. Este agente √© o "olho" do sistema, capaz de entender o conte√∫do visual.

#### 4. O Engenheiro (C√≥digo)
* **Agente:** `agent_code.yaml`
* **Modelo:** `deepseek code 16b` (Modelo MoE)
* **Fun√ß√£o:** Refatora√ß√£o e Gera√ß√£o de C√≥digo.
* **An√°lise:** Um modelo de Mistura de Especialistas (MoE) focado **puramente em tarefas de c√≥digo**. √â leve (para 16B) e tem desempenho de n√≠vel de produ√ß√£o para gerar, analisar e depurar c√≥digo.

#### 5. O Assistente (Conversa)
* **Agente:** `agent_assistant.yaml`
* **Modelo:** `mistral:7b-instruct`
* **Fun√ß√£o:** Assistente Geral.
* **An√°lise:** Famoso por ser um dos modelos mais **r√°pidos, eficientes e competentes** para conversa√ß√£o geral, resumo e resposta a perguntas. √â o assistente de "linha de frente" para intera√ß√µes r√°pidas.
