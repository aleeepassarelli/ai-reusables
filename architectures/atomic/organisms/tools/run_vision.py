#!/usr/bin/env python
# -----------------------------------------------------------------
# üß© Atomic Architecture - Ferramenta de Vis√£o
# organisms/tools/run_vision.py
# -----------------------------------------------------------------
#
# Este script √© uma "ferramenta local" executada pelo AtomicEngine.
# Ele √© chamado pelo 'agent_vision.yaml' (type: "llm_chat", mas pode ser 'local_tool').
#
# 1. Recebe um JSON do 'stdin' (do engine) contendo o 'image_path' e uma 'question'.
# 2. Executa a an√°lise de vis√£o (aqui simulada) usando um VLM.
# 3. Imprime um JSON para o 'stdout' (para o engine).
#
# -----------------------------------------------------------------

import sys
import json
import os

# Em um cen√°rio real, voc√™ importaria o provedor Ollama/Dashscope aqui.
# from organisms.providers_api.ollama_provider import run_qwen_vision # Exemplo
# from organisms.providers_api.dashscope_provider import run_qwen_vision # Exemplo

def read_input_from_stdin():
    """L√™ e parseia o JSON vindo do stdin."""
    try:
        input_data = json.loads(sys.stdin.read())
        
        if not isinstance(input_data, dict):
            raise ValueError("Input (stdin) n√£o √© um objeto JSON.")
            
        required_keys = ['image_path', 'question']
        for key in required_keys:
            if key not in input_data:
                raise ValueError(f"Chave '{key}' ausente no input do stdin.")
        
        return input_data
        
    except json.JSONDecodeError as e:
        print(f"Erro de JSON no stdin: {e}", file=sys.stderr)
        return None
    except ValueError as e:
        print(f"Erro de Valor no stdin: {e}", file=sys.stderr)
        return None

def perform_vision_analysis(image_path: str, question: str):
    """
    Simula o 'qwen 2.5 vision 8b' analisando uma imagem.
    
    Na implementa√ß√£o real, aqui voc√™ usaria o cliente Ollama para
    chamar o modelo Qwen-VL.
    
    Ex:
    response = ollama_client.generate(
        model='qwen:v2.5-8b',
        prompt=question,
        images=[image_path]
    )
    return response['response']
    """
    # Verifica se o arquivo (simulado) existe
    if not os.path.exists(image_path):
        # Em um cen√°rio real, voc√™ faria a verifica√ß√£o.
        # Como o engine j√° tem o path, vamos apenas simular.
        pass

    # --- SIMULA√á√ÉO ---
    # Simula a resposta do Qwen-VL baseada na pergunta.
    if "o que voc√™ v√™" in question.lower() or "descreva a imagem" in question.lower():
        mock_response = (
            f"Eu vejo uma imagem localizada em '{image_path}'. "
            "√â uma cena pitoresca com uma montanha ao fundo, um rio fluindo "
            "e uma pequena cabana na margem. A cor predominante √© verde e azul."
        )
    elif "cores principais" in question.lower():
        mock_response = "As cores principais s√£o verde (vegeta√ß√£o) e azul (c√©u e rio)."
    elif "existem pessoas" in question.lower():
        mock_response = "N√£o consigo identificar pessoas na imagem."
    else:
        mock_response = f"Simula√ß√£o de an√°lise visual para a pergunta: '{question}'. " \
                        "Parece uma bela paisagem natural."
                        
    return mock_response

def write_output_to_stdout(data: dict):
    """Envia o resultado para o stdout como uma string JSON."""
    try:
        json.dump(data, sys.stdout)
    except Exception as e:
        # Se falhar, envia um erro para o stderr
        print(json.dumps({"error": f"Falha ao serializar sa√≠da: {e}"}), file=sys.stderr)

def main():
    input_data = read_input_from_stdin()
    
    if input_data is None:
        write_output_to_stdout({"error": "Falha ao ler o input do stdin para vis√£o."})
        sys.exit(1)

    image_path = input_data['image_path']
    question = input_data['question']

    try:
        # 2. Executa a an√°lise de vis√£o
        vision_analysis_result = perform_vision_analysis(image_path, question)
        
        # 3. Prepara a sa√≠da (conforme esperado pelo 'atomic_engine')
        # A 'output_variable' era 'vision_description'.
        output_data = {
            "vision_description": vision_analysis_result,
            "source_image": image_path,
            "question_asked": question,
            "vlm_model": "qwen:v2.5-8b (simulado)"
        }
        
        # 4. Envia o JSON para o stdout
        write_output_to_stdout(output_data)
        
    except Exception as e:
        write_output_to_stdout({"error": f"Erro durante a an√°lise de vis√£o: {e}"})
        sys.exit(1)

if __name__ == "__main__":
    main()
