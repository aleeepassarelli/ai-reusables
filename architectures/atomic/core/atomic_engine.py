# -----------------------------------------------------------------
# üß© Atomic Architecture - Motor de Orquestra√ß√£o (REFATORADO)
# core/atomic_engine.py
# -----------------------------------------------------------------

import yaml
import os
import json
import subprocess
import ollama
from neo4j import GraphDatabase
from redis import Redis

# --- Importa√ß√µes da Gal√°xia (AI Reusables Framework) ---
# (Assumindo que 'ai_reusables' est√° no PYTHONPATH)
try:
    from ai_reusables.core_engineering.prompt_modular import PromptBuilder
    from ai_reusables.core_engineering.scheme_traductor import SchemeAdapter
    FRAMEWORK_INTEGRADO = True
except ImportError:
    print("‚ö†Ô∏è Framework 'ai_reusables' n√£o encontrado. Rodando em modo de simula√ß√£o.")
    FRAMEWORK_INTEGRADO = False

# --- Constantes de Diret√≥rio (Baseado na sua estrutura) ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MOLECULES_DIR = os.path.join(BASE_DIR, "molecules")
ORGANISMS_DIR = os.path.join(BASE_DIR, "organisms")
TOOLS_DIR = os.path.join(os.path.join(ORGANISMS_DIR, "tools"))

class AtomicEngine:
    """
    O AtomicEngine (SLE Engine) √© o orquestrador central.
    Ele l√™ 'Mol√©culas' (YAMLs de fluxo) e delega a 'Organismos' (Agentes).
    Esta vers√£o √© integrada ao AI Reusables Framework.
    """

    def __init__(self):
        print("Iniciando o AtomicEngine...")
        # --- Conex√µes (Ollama, Neo4j, Redis) ---
        # (O c√≥digo de conex√£o existente vai aqui... omitido por brevidade)
        # ...
        try:
            self.ollama_client = ollama.Client(host='http://localhost:11434')
            self.ollama_client.list()
            print("‚úÖ Conectado ao Ollama.")
        except Exception as e:
            self.ollama_client = None
            print(f"‚ö†Ô∏è Erro ao conectar ao Ollama: {e}.")
        # ... (Neo4j e Redis) ...

        # --- Inicializa os M√≥dulos da Gal√°xia ---
        if FRAMEWORK_INTEGRADO:
            PROMPT_MODULES_PATH = os.path.join(BASE_DIR, "../core_engineering/prompt_modular")
            self.prompt_builder = PromptBuilder(base_path=PROMPT_MODULES_PATH)
            self.scheme_adapter = SchemeAdapter()
            print("‚úÖ Framework (PromptBuilder, SchemeAdapter) integrado.")
        else:
            self.prompt_builder = None
            self.scheme_adapter = None
            print("‚ö†Ô∏è Framework N√ÉO integrado. Funcionalidade limitada.")

    # ... _load_yaml, _load_molecule, _load_organism ...
    # (Estas fun√ß√µes permanecem as mesmas)

    # ... _resolve_input ...
    # (Esta fun√ß√£o permanece a mesma)

    # ... run_chain ...
    # (Esta fun√ß√£o permanece a mesma)

    def _execute_step(self, step_config: dict, agent_config: dict, context: dict):
        """
        O Dispatcher.
        Verifica o 'tipo' de agente e chama a ferramenta correta.
        (Refatorado para simplicidade)
        """
        agent_type = agent_config.get("type")
        
        # Resolve o input (pode vir do trigger ou de outro passo)
        input_data = self._resolve_input(step_config.get("input"), context)
        
        # --- Estrat√©gia 1: Agente LLM (Refatorado) ---
        if agent_type == "llm_chat":
            step_prompt = self._resolve_input(step_config.get("prompt"), context)
            
            return self._run_llm_chat(
                agent_config=agent_config,
                step_prompt=step_prompt,
                context_data=input_data # Passa o contexto resolvido
            )

        # --- Estrat√©gia 2: Ferramenta Interna (Agente MCP) ---
        elif agent_type == "internal_tool":
            tool_name = agent_config.get("function_name") # Ex: "save_to_graph_db"
            return self._run_internal_tool(tool_name, input_data)
            
        # --- Estrat√©gia 3: Script Local (Apenas para ferramentas reais, ex: OCR) ---
        elif agent_type == "local_tool":
            script_path = os.path.join(TOOLS_DIR, agent_config["local_tool_config"]["script_path"])
            return self._run_local_script(script_path, input_data)
            
        else:
            raise ValueError(f"Tipo de Agente desconhecido: {agent_type}")

    # --- Ferramentas de Execu√ß√£o (REFATORADAS) ---

    def _run_llm_chat(self, agent_config: dict, step_prompt: str, context_data: any):
        """
        Chama o cliente Ollama, mas agora usando
        o PromptBuilder e o SchemeAdapter do Framework.
        """
        model = agent_config["llm_config"]["model"]
        print(f"Chamando LLM (Ollama): {model}")
        if not self.ollama_client:
            raise Exception("Cliente Ollama n√£o est√° conectado.")
            
        # 1. Construir o System Prompt (Refatora√ß√£o 2: PromptBuilder)
        if self.prompt_builder and "prompt_modules" in agent_config:
            modules = agent_config["prompt_modules"] # Ex: ['persona/expert.yaml', 'format/json.yaml']
            system_prompt = self.prompt_builder.build(modules)
        else:
            # Fallback para o m√©todo antigo se o framework n√£o for encontrado
            system_prompt = agent_config["llm_config"].get("system_prompt", "Voc√™ √© um assistente prestativo.")

        # 2. Construir o User Prompt (combinando prompt do passo e contexto)
        # O 'context_data' √© o output do passo anterior (ex: o markdown do OCR)
        # O 'step_prompt' √© a instru√ß√£o do 'molecules/*.yaml'
        user_prompt = f"Contexto para analisar:\n---\n{context_data}\n---\n\nTarefa:\n{step_prompt}"
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        response = self.ollama_client.chat(model=model, messages=messages)
        content = response['message']['content']
        
        # 3. For√ßar o Esquema (Refatora√ß√£o 3: SchemeAdapter)
        output_schema = agent_config.get("output_schema", "text")
        
        if output_schema == "json" and self.scheme_adapter:
            # Usa o 'SchemeAdapter' para limpar e validar o JSON
            return self.scheme_adapter.map_schema_from_text(content)
        
        # Fallback se o 'SchemeAdapter' falhar ou n√£o for JSON
        if output_schema == "json" and (content.strip().startswith('{') or content.strip().startswith('[')):
             try:
                return json.loads(content)
             except json.JSONDecodeError:
                pass # Cai para o raw_text
                
        return {"raw_text": content}

    # ... _run_internal_tool ...
    # (Esta fun√ß√£o permanece a mesma)

    # ... _run_local_script ...
    # (Esta fun√ß√£o permanece a mesma)
